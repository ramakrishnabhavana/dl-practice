{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "M9JgKfz-rXcl"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ramakrishnabhavana/dl-practice/blob/main/DL_Lab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#week1"
      ],
      "metadata": {
        "id": "M9JgKfz-rXcl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "298rbYNposRQ",
        "outputId": "195205a5-c225-487c-9534-dfe67d9c291d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: keras in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.12/dist-packages (from keras) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from keras) (2.0.2)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras) (0.1.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.12/dist-packages (from keras) (3.15.1)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras) (0.18.0)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.12/dist-packages (from keras) (0.5.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from keras) (25.0)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.12/dist-packages (from optree->keras) (4.15.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "pip install keras"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Simple Neural Network with PyTorch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "x = torch.randn(100, 3)\n",
        "y = torch.randn(100, 1)\n",
        "class SimpleNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.linear = nn.Linear(3, 1)\n",
        "    def forward(self, x):\n",
        "        return self.linear(x)\n",
        "model = SimpleNet()\n",
        "loss_fn = nn.MSELoss()\n",
        "optimizer = optim.Adam(\n",
        "    model.parameters(),\n",
        "    lr=0.01\n",
        ")\n",
        "for epoch in range(100):\n",
        "    y_pred = model(x)\n",
        "    loss = loss_fn(y_pred, y)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "print(\"Final loss:\", loss.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nc2QPMFH3fnh",
        "outputId": "73635ba8-a1e7-47d3-9264-8a9023a5a327"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final loss: 0.8709965348243713\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Simple Neural Network with TensorFlow\n",
        "import tensorflow as tf\n",
        "x = tf.random.normal((100, 3))\n",
        "y = tf.random.normal((100, 1))\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(1,\n",
        "                          input_shape=(3,))\n",
        "])\n",
        "model.compile(optimizer='adam',             # Configures the Adam optimizer for training\n",
        "              loss='mse')\n",
        "\n",
        "# Train model\n",
        "model.fit(x, y,                             # Trains the model using input and target data\n",
        "          epochs=100,                       # Number of training iterations over the dataset\n",
        "          verbose=0)                        # Suppresses training progress output\n",
        "\n",
        "print(\"Final loss:\",                       # Prints a message label\n",
        "      model.evaluate(x, y))                # Evaluates the trained model on the same dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XKR1psZa4K-p",
        "outputId": "3bc15272-40e2-4443-dea3-73952db5d4bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 1.3640\n",
            "Final loss: 1.551206350326538\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# IMPLEMENT A SIMPLE PERCEPTRON (Coding a Neuron)\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "def sigmoid(x):\n",
        "  return 1 / (1 + np.exp(-x))\n",
        "class Neuron:\n",
        "  def __init__(self, weights, bias):\n",
        "    self.weights = weights\n",
        "    self.bias = bias\n",
        "  def feedforward(self, inputs):\n",
        "    total = np.dot(self.weights, inputs) + self.bias\n",
        "    return sigmoid(total)\n",
        "weights = np.array([0, 1])\n",
        "bias = 4\n",
        "n = Neuron(weights, bias)\n",
        "x = np.array([2, 3])\n",
        "print(n.feedforward(x))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nl29o4oCo5-W",
        "outputId": "2a74da75-598e-4719-c58b-6cdb2da1b82a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9990889488055994\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#AND gate\n",
        "import numpy as np\n",
        "def step(x):\n",
        "    return 1 if x >= 0 else 0\n",
        "\n",
        "class Perceptron:\n",
        "    def __init__(self, weights, bias):\n",
        "        self.weights = weights\n",
        "        self.bias = bias\n",
        "\n",
        "    def predict(self, inputs):\n",
        "        total = np.dot(self.weights, inputs) + self.bias\n",
        "        return step(total)\n",
        "weights = np.array([1, 1])\n",
        "bias = -1.5\n",
        "and_gate = Perceptron(weights, bias)\n",
        "\n",
        "print(\"AND Gate\")\n",
        "for x in [(0,0), (0,1), (1,0), (1,1)]:\n",
        "    print(x, \"->\", and_gate.predict(np.array(x)))"
      ],
      "metadata": {
        "id": "vm4IA23Z3UPS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7982813-4588-4f82-8fdc-c9c7eb0c3637"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AND Gate\n",
            "(0, 0) -> 0\n",
            "(0, 1) -> 0\n",
            "(1, 0) -> 0\n",
            "(1, 1) -> 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#OR Gate\n",
        "weights = np.array([1,1])\n",
        "bias=-0.5\n",
        "or_gate=Perceptron(weights,bias)\n",
        "print(\"\\nOR Gate\")\n",
        "for x in [(0,0),(0,1),(1,0),(1,1)]:\n",
        "  print(x,\"->\",or_gate.predict(np.array(x)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N8HN-od_nqOq",
        "outputId": "a6b21a01-575e-475a-a068-ec314ac6fc9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "OR Gate\n",
            "(0, 0) -> 0\n",
            "(0, 1) -> 1\n",
            "(1, 0) -> 1\n",
            "(1, 1) -> 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#xor using step activation\n",
        "import numpy as np\n",
        "def step(x):\n",
        "  return 1 if x>=0 else 0\n",
        "class XOR_network:\n",
        "  def __init__(self):\n",
        "    self.w_or = np.array([1,1])\n",
        "    self.b_or = -0.5\n",
        "    self.w_and = np.array([1,1])\n",
        "    self.b_and = -1.5\n",
        "    self.w_out=np.array([1,-2])\n",
        "    self.b_out= -0.5\n",
        "  def predict(self,x):\n",
        "    h1 = step(np.dot(self.w_or,x)+self.b_or)\n",
        "    h2 = step(np.dot(self.w_and,x)+self.b_and)\n",
        "    output = step(self.w_out[0]*h1 + self.w_out[1]*h2 + self.b_out)\n",
        "    return output\n",
        "class NOT_gate:\n",
        "    def __init__(self):\n",
        "        self.w = -1\n",
        "        self.b = 0.5\n",
        "    def predict(self, x):\n",
        "        return step(self.w * x + self.b)\n",
        "xor = XOR_network()\n",
        "not_gate = NOT_gate()\n",
        "print(\"XOR and ¬XOR Gates\")\n",
        "for x in [(0,0), (0,1), (1,0), (1,1)]:\n",
        "    xor_out = xor.predict(np.array(x))\n",
        "    not_xor_out = not_gate.predict(xor_out)\n",
        "    print(f\"{x} -> XOR: {xor_out}, ¬XOR: {not_xor_out}\")"
      ],
      "metadata": {
        "id": "YfKAws4losov",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aeec9266-4d2c-4051-e09d-81307a9d93c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XOR and ¬XOR Gates\n",
            "(0, 0) -> XOR: 0, ¬XOR: 1\n",
            "(0, 1) -> XOR: 1, ¬XOR: 0\n",
            "(1, 0) -> XOR: 1, ¬XOR: 0\n",
            "(1, 1) -> XOR: 0, ¬XOR: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#XOR Training Using Gradient Descent\n",
        "import numpy as np\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "def sigmoid_derivative(x):\n",
        "    return x * (1 - x)\n",
        "X = np.array([\n",
        "    [0, 0],\n",
        "    [0, 1],\n",
        "    [1, 0],\n",
        "    [1, 1]\n",
        "])\n",
        "y = np.array([[0], [1], [1], [0]])\n",
        "np.random.seed(42)\n",
        "W1 = np.random.rand(2, 2)\n",
        "b1 = np.random.rand(1, 2)\n",
        "W2 = np.random.rand(2, 1)\n",
        "b2 = np.random.rand(1, 1)\n",
        "learning_rate = 0.1\n",
        "epochs = 10000\n",
        "for epoch in range(epochs):\n",
        "    hidden_input = np.dot(X, W1) + b1\n",
        "    hidden_output = sigmoid(hidden_input)\n",
        "    final_input = np.dot(hidden_output, W2) + b2\n",
        "    y_pred = sigmoid(final_input)\n",
        "    error = y - y_pred\n",
        "    loss = np.mean(error ** 2)\n",
        "    d_output = error * sigmoid_derivative(y_pred)\n",
        "    d_hidden = d_output.dot(W2.T) * sigmoid_derivative(hidden_output)\n",
        "    W2 += hidden_output.T.dot(d_output) * learning_rate\n",
        "    b2 += np.sum(d_output, axis=0, keepdims=True) * learning_rate\n",
        "\n",
        "    W1 += X.T.dot(d_hidden) * learning_rate\n",
        "    b1 += np.sum(d_hidden, axis=0, keepdims=True) * learning_rate\n",
        "    if epoch % 1000 == 0:\n",
        "        print(f\"Epoch {epoch}, Loss: {loss:.4f}\")\n",
        "print(\"\\nXOR Predictions after Training:\")\n",
        "for i in range(len(X)):\n",
        "    print(X[i], \"->\", round(y_pred[i][0]))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zxKzMbFYysKi",
        "outputId": "068b0173-d0e7-4931-e7b1-375c4d45039e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Loss: 0.3247\n",
            "Epoch 1000, Loss: 0.2406\n",
            "Epoch 2000, Loss: 0.1960\n",
            "Epoch 3000, Loss: 0.1207\n",
            "Epoch 4000, Loss: 0.0305\n",
            "Epoch 5000, Loss: 0.0125\n",
            "Epoch 6000, Loss: 0.0074\n",
            "Epoch 7000, Loss: 0.0051\n",
            "Epoch 8000, Loss: 0.0038\n",
            "Epoch 9000, Loss: 0.0031\n",
            "\n",
            "XOR Predictions after Training:\n",
            "[0 0] -> 0\n",
            "[0 1] -> 1\n",
            "[1 0] -> 1\n",
            "[1 1] -> 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#WEEK 2"
      ],
      "metadata": {
        "id": "24GGhYDXrbmU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#demonstrate thresholding is harsh\n",
        "import numpy as np\n",
        "def step(x):\n",
        "  return 1 if x >= 0 else 0\n",
        "class Neuron:\n",
        "  def __init__(self, weights, bias):\n",
        "    self.weights = weights\n",
        "    self.bias = bias\n",
        "  def feedforward(self, inputs):\n",
        "    total = np.dot(self.weights, inputs) + self.bias\n",
        "    return step(total)\n",
        "weights = np.array([0, 1])\n",
        "b_1 = -3.1\n",
        "b_2 = 2\n",
        "b_3 = -3.0\n",
        "n = Neuron(weights, b_1)\n",
        "n_2 = Neuron(weights, b_2)\n",
        "n_3 = Neuron(weights,b_3)\n",
        "x = np.array([2, 3])\n",
        "print(\"with bias -3.1:\",n.feedforward(x))\n",
        "print(\"\\nwith bias -3.0:\",n_3.feedforward(x))\n",
        "print(\"\\nwith bias 2:\",n_2.feedforward(x))"
      ],
      "metadata": {
        "id": "R4JAT_SrrcRz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c616e81d-5339-48c8-9a14-ff34878668a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "with bias -3.1: 0\n",
            "\n",
            "with bias -3.0: 1\n",
            "\n",
            "with bias 2: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "dl = pd.read_csv(\"/content/dl-week2 - Sheet1.csv\")\n",
        "X = dl['f1','f2','f3','f4']\n",
        "y=dl['output'].values\n",
        "x_train,x_test,y_train,y_test = train_test_split(X,y,test_size=0.3,random_state=42)\n",
        "\n",
        "def step(z):\n",
        "  return 1 if z>=0 else 0\n"
      ],
      "metadata": {
        "id": "DX6CBiUt2oOw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# XOR and XNOR implementation using a Multi-Perceptron Network\n",
        "\n",
        "# Step activation function\n",
        "def step(x):\n",
        "    return 1 if x >= 0 else 0\n",
        "\n",
        "# Hidden layer perceptrons\n",
        "def OR(x1, x2):\n",
        "    w1, w2, b = 1, 1, -0.5\n",
        "    return step(w1*x1 + w2*x2 + b)\n",
        "\n",
        "def AND(x1, x2):\n",
        "    w1, w2, b = 1, 1, -1.5\n",
        "    return step(w1*x1 + w2*x2 + b)\n",
        "\n",
        "# XOR using multi-perceptron\n",
        "def XOR(x1, x2):\n",
        "    h1 = OR(x1, x2)\n",
        "    h2 = AND(x1, x2)\n",
        "    w1, w2, b = 1, -2, -0.5\n",
        "    return step(w1*h1 + w2*h2 + b)\n",
        "\n",
        "# XNOR (NOT XOR)\n",
        "def XNOR(x1, x2):\n",
        "    return 1 - XOR(x1, x2)\n",
        "\n",
        "# Testing the network\n",
        "print(\"X1 X2 XOR XNOR\")\n",
        "for x1 in [0, 1]:\n",
        "    for x2 in [0, 1]:\n",
        "        print(x1, x2, \" \", XOR(x1, x2), \" \", XNOR(x1, x2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YwQFtcmzFyWx",
        "outputId": "284024f8-15d0-4ea7-ad0e-0579f080185f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X1 X2 XOR XNOR\n",
            "0 0   0   1\n",
            "0 1   1   0\n",
            "1 0   1   0\n",
            "1 1   0   1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# -------------------------------------------------------\n",
        "# STEP 1: Create a small movie dataset and save as CSV\n",
        "# -------------------------------------------------------\n",
        "\n",
        "data = {\n",
        "    \"MattDamon\": [1, 0, 1, 0, 1, 0, 1, 0],\n",
        "    \"Thriller\":  [1, 1, 0, 0, 1, 0, 0, 1],\n",
        "    \"Nolan\":     [0, 1, 0, 1, 1, 0, 0, 1],\n",
        "    \"IMDB\":      [0.9, 0.8, 0.6, 0.4, 0.85, 0.3, 0.7, 0.5],\n",
        "    \"Like\":      [1, 1, 1, 0, 1, 0, 1, 0]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "df.to_csv(\"movies.csv\", index=False)\n",
        "\n",
        "print(\"Movie Dataset:\")\n",
        "print(df)\n",
        "\n",
        "X = df.drop(\"Like\", axis=1).values\n",
        "y = df[\"Like\"].values\n",
        "\n",
        "# -------------------------------------------------------\n",
        "# STEP 2: Activation Function\n",
        "# -------------------------------------------------------\n",
        "\n",
        "def step(x):\n",
        "    return 1 if x >= 0 else 0\n",
        "\n",
        "# -------------------------------------------------------\n",
        "# i) MP Perceptron (No weights, No bias)\n",
        "# -------------------------------------------------------\n",
        "\n",
        "def mp_perceptron_predict(x):\n",
        "    return step(np.sum(x))   # equal importance to all features\n",
        "\n",
        "print(\"\\n--- MP Perceptron (No weights, No bias) ---\")\n",
        "for i, x in enumerate(X):\n",
        "    print(f\"Actual: {y[i]}  Predicted: {mp_perceptron_predict(x)}\")\n",
        "\n",
        "# -------------------------------------------------------\n",
        "# ii) Perceptron with weights only (No bias)\n",
        "# -------------------------------------------------------\n",
        "\n",
        "def train_perceptron_no_bias(X, y, lr=0.1, epochs=10):\n",
        "    w = np.zeros(X.shape[1])\n",
        "    print(\"\\nTraining Perceptron (Weights only)\")\n",
        "    for epoch in range(epochs):\n",
        "        errors = 0\n",
        "        for i in range(len(X)):\n",
        "            y_pred = step(np.dot(X[i], w))\n",
        "            error = y[i] - y_pred\n",
        "            if error != 0:\n",
        "                w = w + lr * error * X[i]\n",
        "                errors += 1\n",
        "        print(f\"Epoch {epoch+1}, Weights: {w}, Errors: {errors}\")\n",
        "        if errors == 0:\n",
        "            break\n",
        "    return w\n",
        "\n",
        "w_no_bias = train_perceptron_no_bias(X, y)\n",
        "\n",
        "# -------------------------------------------------------\n",
        "# iii) Perceptron with weights and bias\n",
        "# -------------------------------------------------------\n",
        "\n",
        "def train_perceptron_with_bias(X, y, lr=0.1, epochs=10):\n",
        "    w = np.zeros(X.shape[1])\n",
        "    b = 0\n",
        "    print(\"\\nTraining Perceptron (Weights + Bias)\")\n",
        "    for epoch in range(epochs):\n",
        "        errors = 0\n",
        "        for i in range(len(X)):\n",
        "            y_pred = step(np.dot(X[i], w) + b)\n",
        "            error = y[i] - y_pred\n",
        "            if error != 0:\n",
        "                w = w + lr * error * X[i]\n",
        "                b = b + lr * error\n",
        "                errors += 1\n",
        "        print(f\"Epoch {epoch+1}, Weights: {w}, Bias: {b}, Errors: {errors}\")\n",
        "        if errors == 0:\n",
        "            break\n",
        "    return w, b\n",
        "\n",
        "w_bias, b_bias = train_perceptron_with_bias(X, y)\n",
        "\n",
        "# -------------------------------------------------------\n",
        "# STEP 3: Test with a sample movie\n",
        "# -------------------------------------------------------\n",
        "\n",
        "sample_movie = np.array([1, 1, 0, 0.8])  # Matt Damon, Thriller, Not Nolan, High IMDB\n",
        "\n",
        "print(\"\\n--- Testing Sample Movie ---\")\n",
        "print(\"Sample features:\", sample_movie)\n",
        "\n",
        "print(\"MP Perceptron Prediction:\", mp_perceptron_predict(sample_movie))\n",
        "print(\"Perceptron (Weights only):\", step(np.dot(sample_movie, w_no_bias)))\n",
        "print(\"Perceptron (Weights + Bias):\", step(np.dot(sample_movie, w_bias) + b_bias))"
      ],
      "metadata": {
        "id": "PU_pfcSuJAag",
        "outputId": "3743b5a7-bf64-4d00-f8d4-52f45c77a55a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Movie Dataset:\n",
            "   MattDamon  Thriller  Nolan  IMDB  Like\n",
            "0          1         1      0  0.90     1\n",
            "1          0         1      1  0.80     1\n",
            "2          1         0      0  0.60     1\n",
            "3          0         0      1  0.40     0\n",
            "4          1         1      1  0.85     1\n",
            "5          0         0      0  0.30     0\n",
            "6          1         0      0  0.70     1\n",
            "7          0         1      1  0.50     0\n",
            "\n",
            "--- MP Perceptron (No weights, No bias) ---\n",
            "Actual: 1  Predicted: 1\n",
            "Actual: 1  Predicted: 1\n",
            "Actual: 1  Predicted: 1\n",
            "Actual: 0  Predicted: 1\n",
            "Actual: 1  Predicted: 1\n",
            "Actual: 0  Predicted: 1\n",
            "Actual: 1  Predicted: 1\n",
            "Actual: 0  Predicted: 1\n",
            "\n",
            "Training Perceptron (Weights only)\n",
            "Epoch 1, Weights: [ 0.1    0.    -0.1   -0.035], Errors: 4\n",
            "Epoch 2, Weights: [ 0.1    0.1   -0.1   -0.025], Errors: 3\n",
            "Epoch 3, Weights: [ 0.1    0.1   -0.2   -0.065], Errors: 4\n",
            "Epoch 4, Weights: [ 0.1    0.1   -0.2   -0.065], Errors: 3\n",
            "Epoch 5, Weights: [ 0.1    0.1   -0.2   -0.065], Errors: 3\n",
            "Epoch 6, Weights: [ 0.1    0.1   -0.2   -0.065], Errors: 3\n",
            "Epoch 7, Weights: [ 0.1    0.1   -0.2   -0.065], Errors: 3\n",
            "Epoch 8, Weights: [ 0.1    0.1   -0.2   -0.065], Errors: 3\n",
            "Epoch 9, Weights: [ 0.1    0.1   -0.2   -0.065], Errors: 3\n",
            "Epoch 10, Weights: [ 0.1    0.1   -0.2   -0.065], Errors: 3\n",
            "\n",
            "Training Perceptron (Weights + Bias)\n",
            "Epoch 1, Weights: [ 0.1    0.    -0.1   -0.035], Bias: -0.2, Errors: 4\n",
            "Epoch 2, Weights: [ 0.2    0.1   -0.2    0.045], Bias: -0.2, Errors: 4\n",
            "Epoch 3, Weights: [ 0.2    0.1   -0.2    0.075], Bias: -0.2, Errors: 2\n",
            "Epoch 4, Weights: [ 0.2    0.1   -0.2    0.105], Bias: -0.2, Errors: 2\n",
            "Epoch 5, Weights: [ 0.2    0.1   -0.2    0.135], Bias: -0.2, Errors: 2\n",
            "Epoch 6, Weights: [ 0.2    0.1   -0.2    0.165], Bias: -0.2, Errors: 2\n",
            "Epoch 7, Weights: [ 0.2    0.1   -0.2    0.195], Bias: -0.2, Errors: 2\n",
            "Epoch 8, Weights: [ 0.2    0.1   -0.2    0.225], Bias: -0.2, Errors: 2\n",
            "Epoch 9, Weights: [ 0.2    0.1   -0.2    0.255], Bias: -0.2, Errors: 2\n",
            "Epoch 10, Weights: [ 0.2    0.1   -0.2    0.255], Bias: -0.30000000000000004, Errors: 3\n",
            "\n",
            "--- Testing Sample Movie ---\n",
            "Sample features: [1.  1.  0.  0.8]\n",
            "MP Perceptron Prediction: 1\n",
            "Perceptron (Weights only): 1\n",
            "Perceptron (Weights + Bias): 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#WEEK-3"
      ],
      "metadata": {
        "id": "xVen6yonrc4m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Input patterns\n",
        "X = np.array([\n",
        "    [0, 0],\n",
        "    [0, 1],\n",
        "    [1, 0],\n",
        "    [1, 1]\n",
        "])\n",
        "\n",
        "# All 16 Boolean functions (outputs)\n",
        "boolean_functions = {\n",
        "    \"f1\":  [0,0,0,0],\n",
        "    \"f2\":  [0,0,0,1],   # AND\n",
        "    \"f3\":  [0,0,1,0],\n",
        "    \"f4\":  [0,0,1,1],\n",
        "    \"f5\":  [0,1,0,0],\n",
        "    \"f6\":  [0,1,0,1],\n",
        "    \"f7\":  [0,1,1,0],   # XOR\n",
        "    \"f8\":  [0,1,1,1],\n",
        "    \"f9\":  [1,0,0,0],\n",
        "    \"f10\": [1,0,0,1],   # XNOR\n",
        "    \"f11\": [1,0,1,0],\n",
        "    \"f12\": [1,0,1,1],\n",
        "    \"f13\": [1,1,0,0],\n",
        "    \"f14\": [1,1,0,1],\n",
        "    \"f15\": [1,1,1,0],\n",
        "    \"f16\": [1,1,1,1]\n",
        "}\n",
        "\n",
        "# Step function\n",
        "def step(x):\n",
        "    return 1 if x >= 0 else 0\n",
        "\n",
        "# Train single perceptron\n",
        "def train_perceptron(X, y, lr=0.1, epochs=50):\n",
        "    w = np.zeros(X.shape[1])\n",
        "    b = 0\n",
        "\n",
        "    for _ in range(epochs):\n",
        "        error_count = 0\n",
        "        for i in range(len(X)):\n",
        "            y_pred = step(np.dot(X[i], w) + b)\n",
        "            error = y[i] - y_pred\n",
        "            if error != 0:\n",
        "                w += lr * error * X[i]\n",
        "                b += lr * error\n",
        "                error_count += 1\n",
        "        if error_count == 0:\n",
        "            return True   # Converged\n",
        "\n",
        "    return False  # Did not converge\n",
        "\n",
        "# Test all Boolean functions\n",
        "not_learnable = []\n",
        "\n",
        "print(\"Perceptron Learning Results:\\n\")\n",
        "\n",
        "for fname, outputs in boolean_functions.items():\n",
        "    y = np.array(outputs)\n",
        "    converged = train_perceptron(X, y)\n",
        "    result = \"Learnable\" if converged else \"NOT Learnable\"\n",
        "    print(f\"{fname}: {result}\")\n",
        "    if not converged:\n",
        "        not_learnable.append(fname)\n",
        "\n",
        "print(\"\\nSummary:\")\n",
        "print(\"Total Boolean functions:\", len(boolean_functions))\n",
        "print(\"Learnable:\", len(boolean_functions) - len(not_learnable))\n",
        "print(\"Not Learnable:\", len(not_learnable))\n",
        "print(\"Not Learnable Functions:\", not_learnable)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6hgvtBiXrin2",
        "outputId": "3d9ef2b2-eb18-4cba-93ad-99599bffa772"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Perceptron Learning Results:\n",
            "\n",
            "f1: Learnable\n",
            "f2: Learnable\n",
            "f3: Learnable\n",
            "f4: Learnable\n",
            "f5: Learnable\n",
            "f6: Learnable\n",
            "f7: NOT Learnable\n",
            "f8: Learnable\n",
            "f9: Learnable\n",
            "f10: NOT Learnable\n",
            "f11: Learnable\n",
            "f12: Learnable\n",
            "f13: Learnable\n",
            "f14: Learnable\n",
            "f15: Learnable\n",
            "f16: Learnable\n",
            "\n",
            "Summary:\n",
            "Total Boolean functions: 16\n",
            "Learnable: 14\n",
            "Not Learnable: 2\n",
            "Not Learnable Functions: ['f7', 'f10']\n"
          ]
        }
      ]
    }
  ]
}